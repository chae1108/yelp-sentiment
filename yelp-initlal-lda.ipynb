{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"type\": \"review\", \"business_id\": \"1CBs84C-a-cuA3vncXVSAw\", \"votes\": {\"cool\": 0, \"useful\": 0, \"funny\": 0}, \"review_id\": \"0a-pCW4guXIlWNpVeBHChg\", \"text\": \"The pizza is terrible, but if you need a place to watch a game or just down some pitchers, this place works.\\n\\nOh, and the pasta is even worse than the pizza.\", \"stars\": 2, \"user_id\": \"90wm_01FAIqhcgV_mPON9Q\", \"date\": \"2006-07-26\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import codecs\n",
    "\n",
    "data_directory = os.path.join('dataset')\n",
    "review_filepath = os.path.join(data_directory,\n",
    "                                   'reviews2.json')\n",
    "\n",
    "with codecs.open(review_filepath, encoding='utf_8') as f:\n",
    "    first_business_record = f.readline() \n",
    "\n",
    "print first_business_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4135daf517fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresult_directory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'result'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m review_txt_filepath = os.path.join(result_directory,\n\u001b[1;32m      5\u001b[0m                                    'review_text.txt')\n",
      "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "result_directory = os.path.join('result')\n",
    "review_txt_filepath = os.path.join(result_directory,\n",
    "                                   'review_text.txt')\n",
    "review_count = 0\n",
    "    \n",
    "with codecs.open(review_txt_filepath, 'w', encoding='utf_8') as review_txt_file:\n",
    "    with codecs.open(review_filepath, encoding='utf_8') as review_file:\n",
    "        for review_json in review_file:\n",
    "            review = json.loads(review_json)\n",
    "            review_txt_file.write(review[u'text'].replace('\\n', '\\\\n') + '\\n')\n",
    "            review_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Their margherita pizza is great! Don't get their pastas--they're badly made, I can make way better pasta. There's sports on and a pool table. The prices are good but unfortunately there's no discount for buying in bulk really.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with codecs.open(review_txt_filepath, encoding='utf_8') as f:\n",
    "    sample_review = list(it.islice(f, 8, 9))[0]\n",
    "    sample_review = sample_review.replace('\\\\n', '\\n')\n",
    "        \n",
    "print sample_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.75 ms, sys: 0 ns, total: 5.75 ms\n",
      "Wall time: 4.67 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "parsed_review = nlp(sample_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Their margherita pizza is great! Don't get their pastas--they're badly made, I can make way better pasta. There's sports on and a pool table. The prices are good but unfortunately there's no discount for buying in bulk really.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print parsed_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1:\n",
      "Their margherita pizza is great!\n",
      "\n",
      "Sentence 2:\n",
      "Don't get their pastas--\n",
      "\n",
      "Sentence 3:\n",
      "they're badly made, I can make way better pasta.\n",
      "\n",
      "Sentence 4:\n",
      "There's sports on and a pool table.\n",
      "\n",
      "Sentence 5:\n",
      "The prices are good but unfortunately there's no discount for buying in bulk really.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for num, sentence in enumerate(parsed_review.sents):\n",
    "    print 'Sentence {}:'.format(num+1)\n",
    "    print sentence\n",
    "    print ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_lemma = [token.lemma_ for token in parsed_review]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'their',\n",
       " u'margherita',\n",
       " u'pizza',\n",
       " u'be',\n",
       " u'great',\n",
       " u'!',\n",
       " u'do',\n",
       " u'not',\n",
       " u'get',\n",
       " u'their',\n",
       " u'pasta',\n",
       " u'--',\n",
       " u\"they're\",\n",
       " u'badly',\n",
       " u'make',\n",
       " u',',\n",
       " u'i',\n",
       " u'can',\n",
       " u'make',\n",
       " u'way',\n",
       " u'better',\n",
       " u'pasta',\n",
       " u'.',\n",
       " u'there',\n",
       " u\"'\",\n",
       " u'sport',\n",
       " u'on',\n",
       " u'and',\n",
       " u'a',\n",
       " u'pool',\n",
       " u'table',\n",
       " u'.',\n",
       " u'the',\n",
       " u'price',\n",
       " u'be',\n",
       " u'good',\n",
       " u'but',\n",
       " u'unfortunately',\n",
       " u'there',\n",
       " u\"'\",\n",
       " u'no',\n",
       " u'discount',\n",
       " u'for',\n",
       " u'buy',\n",
       " u'in',\n",
       " u'bulk',\n",
       " u'really',\n",
       " u'.',\n",
       " u'\\n']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"gensim.models.word2vec\"\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Phrases\n",
    "from gensim.models.word2vec import LineSentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def punct_space(token):\n",
    "    return token.is_punct or token.is_space\n",
    "\n",
    "def line_review(filename):\n",
    "    with codecs.open(filename, encoding='utf_8') as f:\n",
    "        for review in f:\n",
    "            yield review.replace('\\\\n', '\\n')\n",
    "            \n",
    "def lemmatized_sentence_corpus(filename):\n",
    "    for parsed_review in nlp.pipe(line_review(filename), batch_size=10000, n_threads=4):        \n",
    "        for sent in parsed_review.sents:\n",
    "            yield u' '.join([token.lemma_ for token in sent\n",
    "                             if not punct_space(token)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unigram_sentences_filepath = os.path.join(result_directory,'unigram_sentences_all.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with codecs.open(unigram_sentences_filepath, 'w', encoding='utf_8') as f:\n",
    "    for sentence in lemmatized_sentence_corpus(review_txt_filepath):\n",
    "        f.write(sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unigram_sentences = LineSentence(unigram_sentences_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i mostly come here to use their change machine\n",
      "\n",
      "they have about 20+ thing on tap\n",
      "\n",
      "and if you do not count thing that be not beer e.g. bud they still have about 12+ beer on tap\n",
      "\n",
      "that make me really happy\n",
      "\n",
      "the casual pizza/beer atmosphere be wonderful for a late dinner last night\n",
      "\n",
      "the folk be really nice and the customer be not super crazy either like you would expect sometimes in a college town\n",
      "\n",
      "also they have thing like pool table and arcade machine which make them pretty awesome in my book\n",
      "\n",
      "the pizza be really good\n",
      "\n",
      "we have a special pizza with feta tomato and basil and a basket of fried mushroos and zuccini\n",
      "\n",
      "the wait be reasonable for a pizza make from scratch\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for unigram_sentence in it.islice(unigram_sentences, 230, 240):\n",
    "    print u' '.join(unigram_sentence)\n",
    "    print u''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_model_filepath = os.path.join(result_directory, 'bigram_model_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.55 s, sys: 72.1 ms, total: 4.63 s\n",
      "Wall time: 4.61 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bigram_model = Phrases(unigram_sentences)\n",
    "bigram_model.save(bigram_model_filepath)\n",
    "\n",
    "bigram_model = Phrases.load(bigram_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_sentences_filepath = os.path.join(result_directory,'bigram_sentences_all.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with codecs.open(bigram_sentences_filepath, 'w', encoding='utf_8') as f:\n",
    "\n",
    "    for unigram_sentence in unigram_sentences:\n",
    "\n",
    "        bigram_sentence = u' '.join(bigram_model[unigram_sentence])\n",
    "\n",
    "        f.write(bigram_sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bigram_sentences = LineSentence(bigram_sentences_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i mostly come_here to use their change machine\n",
      "\n",
      "they have about 20+ thing on_tap\n",
      "\n",
      "and if_you do not count thing that be not beer e.g. bud they still have about 12+ beer on_tap\n",
      "\n",
      "that make me really happy\n",
      "\n",
      "the casual pizza/beer atmosphere be wonderful for a late dinner last_night\n",
      "\n",
      "the folk be really nice and the customer be not super crazy either like you would expect sometimes in a college_town\n",
      "\n",
      "also they have thing like pool_table and arcade machine which make them pretty awesome in my book\n",
      "\n",
      "the pizza be really good\n",
      "\n",
      "we have a special pizza with feta tomato and basil and a basket of fried mushroos and zuccini\n",
      "\n",
      "the wait be reasonable for a pizza make from_scratch\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for bigram_sentence in it.islice(bigram_sentences, 230, 240):\n",
    "    print u' '.join(bigram_sentence)\n",
    "    print u''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigram_model_filepath = os.path.join(result_directory,'trigram_model_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigram_model = Phrases(bigram_sentences)\n",
    "\n",
    "trigram_model.save(trigram_model_filepath)\n",
    "    \n",
    "# load the finished model from disk\n",
    "trigram_model = Phrases.load(trigram_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigram_sentences_filepath = os.path.join(result_directory,'trigram_sentences_all.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with codecs.open(trigram_sentences_filepath, 'w', encoding='utf_8') as f:\n",
    "\n",
    "    for bigram_sentence in bigram_sentences:\n",
    "\n",
    "        trigram_sentence = u' '.join(trigram_model[bigram_sentence])\n",
    "\n",
    "        f.write(trigram_sentence + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigram_sentences = LineSentence(trigram_sentences_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i mostly come_here to use their change machine\n",
      "\n",
      "they have about 20+ thing on_tap\n",
      "\n",
      "and if_you do_not count thing that be not beer e.g. bud they still have about 12+ beer_on_tap\n",
      "\n",
      "that make me really happy\n",
      "\n",
      "the casual pizza/beer atmosphere be wonderful for a late dinner last_night\n",
      "\n",
      "the folk be really nice and the customer be not super crazy either like you would expect sometimes in a college_town\n",
      "\n",
      "also they have thing like pool_table and arcade machine which make them pretty awesome in my_book\n",
      "\n",
      "the pizza be really good\n",
      "\n",
      "we have a special pizza with feta tomato and basil and a basket of fried mushroos and zuccini\n",
      "\n",
      "the wait be reasonable for a pizza make from_scratch\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for trigram_sentence in it.islice(trigram_sentences, 230, 240):\n",
    "    print u' '.join(trigram_sentence)\n",
    "    print u''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trigram_reviews_filepath = os.path.join(result_directory,'trigram_transformed_reviews_all.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with codecs.open(trigram_reviews_filepath, 'w', encoding='utf_8') as f:\n",
    "\n",
    "    for parsed_review in nlp.pipe(line_review(review_txt_filepath),\n",
    "                                  batch_size=10000, n_threads=4):\n",
    "\n",
    "        # lemmatize the text, removing punctuation and whitespace\n",
    "        unigram_review = [token.lemma_ for token in parsed_review\n",
    "                          if not punct_space(token)]\n",
    "\n",
    "        # apply the first-order and second-order phrase models\n",
    "        bigram_review = bigram_model[unigram_review]\n",
    "        trigram_review = trigram_model[bigram_review]\n",
    "\n",
    "        # remove any remaining stopwords\n",
    "        trigram_review = [term for term in trigram_review\n",
    "                          if term not in spacy.en.STOPWORDS]\n",
    "\n",
    "        # write the transformed review as a line in the new file\n",
    "        trigram_review = u' '.join(trigram_review)\n",
    "        f.write(trigram_review + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "\n",
      "This is a nice La Val's. It has big screen TVs playing sports and a pool table in the back. The pizza is just ok as always, but the garlic bread is delicious. \n",
      "\n",
      "Back in the days it was nice to take a break from the dreariness of Soda Hall have dinner, and play a game of pool, before going back to program.\n",
      "\n",
      "----\n",
      "\n",
      "Transformed:\n",
      "\n",
      "nice la_val_'s big_screen_tv play_sport pool_table pizza ok garlic_bread delicious day nice break dreariness soda_hall dinner play game pool go_back program\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print u'Original:' + u'\\n'\n",
    "\n",
    "for review in it.islice(line_review(review_txt_filepath), 11, 12):\n",
    "    print review\n",
    "\n",
    "print u'----' + u'\\n'\n",
    "print u'Transformed:' + u'\\n'\n",
    "\n",
    "with codecs.open(trigram_reviews_filepath, encoding='utf_8') as f:\n",
    "    for review in it.islice(f, 11, 12):\n",
    "        print review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import warnings\n",
    "import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigram_dictionary_filepath = os.path.join(result_directory, 'trigram_dict_all.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trigram_reviews = LineSentence(trigram_reviews_filepath)\n",
    "\n",
    "# learn the dictionary by iterating over all of the reviews\n",
    "trigram_dictionary = Dictionary(trigram_reviews)\n",
    "\n",
    "# filter tokens that are very rare or too common from\n",
    "# the dictionary (filter_extremes) and reassign integer ids (compactify)\n",
    "trigram_dictionary.filter_extremes(no_below=10, no_above=0.4)\n",
    "trigram_dictionary.compactify()\n",
    "\n",
    "trigram_dictionary.save(trigram_dictionary_filepath)\n",
    "\n",
    "# load the finished dictionary from disk\n",
    "trigram_dictionary = Dictionary.load(trigram_dictionary_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigram_bow_filepath = os.path.join(result_directory,'trigram_bow_corpus_all.mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trigram_bow_generator(filepath):\n",
    "    for review in LineSentence(filepath):\n",
    "        yield trigram_dictionary.doc2bow(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.06 s, sys: 16 ms, total: 4.07 s\n",
      "Wall time: 4.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# generate bag-of-words representations for\n",
    "# all reviews and save them as a matrix\n",
    "MmCorpus.serialize(trigram_bow_filepath,\n",
    "                   trigram_bow_generator(trigram_reviews_filepath))\n",
    "    \n",
    "# load the finished bag-of-words corpus from disk\n",
    "trigram_bow_corpus = MmCorpus(trigram_bow_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lda_model_filepath = os.path.join(result_directory, 'lda_model_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50.5 s, sys: 3.54 s, total: 54.1 s\n",
      "Wall time: 1min 29s\n"
     ]
    }
   ],
   "source": [
    "# lda\n",
    "%%time\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "\n",
    "    lda = LdaMulticore(trigram_bow_corpus,\n",
    "                       num_topics=50,\n",
    "                       id2word=trigram_dictionary,\n",
    "                       workers=3)\n",
    "\n",
    "lda.save(lda_model_filepath)\n",
    "    \n",
    "# load the finished LDA model from disk\n",
    "lda = LdaMulticore.load(lda_model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def explore_topic(topic_number, topn=25):\n",
    "    print u'{:20} {}'.format(u'term', u'frequency') + u'\\n'\n",
    "\n",
    "    for term, frequency in lda.show_topic(topic_number, topn=25):\n",
    "        print u'{:20} {:.3f}'.format(term, round(frequency, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term                 frequency\n",
      "\n",
      "order                0.012\n",
      "price                0.011\n",
      "food                 0.010\n",
      "do_not               0.010\n",
      "like                 0.009\n",
      "great                0.008\n",
      "nice                 0.007\n",
      "place                0.007\n",
      "sandwich             0.007\n",
      "2                    0.007\n",
      "this_place           0.007\n",
      "love                 0.007\n",
      "'                    0.007\n",
      "pretty               0.007\n",
      "service              0.006\n",
      "chicken              0.006\n",
      "taste                0.005\n",
      "breakfast            0.005\n",
      "home_fries           0.005\n",
      "eat                  0.005\n",
      "dish                 0.005\n",
      "'s                   0.005\n",
      "want                 0.005\n",
      "if_you               0.004\n",
      "location             0.004\n"
     ]
    }
   ],
   "source": [
    "explore_topic(topic_number=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_names = {0: u'mexican',\n",
    "               1: u'menu',\n",
    "               2: u'thai',\n",
    "               3: u'steak',\n",
    "               4: u'donuts & appetizers',\n",
    "               5: u'specials',\n",
    "               6: u'soup',\n",
    "               7: u'wings, sports bar',\n",
    "               8: u'foreign language',\n",
    "               9: u'las vegas',\n",
    "               10: u'chicken',\n",
    "               11: u'aria buffet',\n",
    "               12: u'noodles',\n",
    "               13: u'ambience & seating',\n",
    "               14: u'sushi',\n",
    "               15: u'arizona',\n",
    "               16: u'family',\n",
    "               17: u'price',\n",
    "               18: u'sweet',\n",
    "               19: u'waiting',\n",
    "               20: u'general',\n",
    "               21: u'tapas',\n",
    "               22: u'dirty',\n",
    "               23: u'customer service',\n",
    "               24: u'restrooms',\n",
    "               25: u'chinese',\n",
    "               26: u'gluten free',\n",
    "               27: u'pizza',\n",
    "               28: u'seafood',\n",
    "               29: u'amazing',\n",
    "               30: u'eat, like, know, want',\n",
    "               31: u'bars',\n",
    "               32: u'breakfast',\n",
    "               33: u'location & time',\n",
    "               34: u'italian',\n",
    "               35: u'barbecue',\n",
    "               36: u'arizona',\n",
    "               37: u'indian',\n",
    "               38: u'latin & cajun',\n",
    "               39: u'burger & fries',\n",
    "               40: u'vegetarian',\n",
    "               41: u'lunch buffet',\n",
    "               42: u'customer service',\n",
    "               43: u'taco, ice cream',\n",
    "               44: u'high cuisine',\n",
    "               45: u'healthy',\n",
    "               46: u'salad & sandwich',\n",
    "               47: u'greek',\n",
    "               48: u'poor experience',\n",
    "               49: u'wine & dine'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic_names_filepath = os.path.join(result_directory, 'topic_names.pkl')\n",
    "\n",
    "with open(topic_names_filepath, 'w') as f:\n",
    "    pickle.dump(topic_names, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LDAvis_data_filepath = os.path.join(result_directory, 'ldavis_prepared')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LDAvis_prepared = pyLDAvis.gensim.prepare(lda, trigram_bow_corpus,\n",
    "                                          trigram_dictionary)\n",
    "\n",
    "with open(LDAvis_data_filepath, 'w') as f:\n",
    "    pickle.dump(LDAvis_prepared, f)\n",
    "        \n",
    "# load the pre-prepared pyLDAvis data from disk\n",
    "with open(LDAvis_data_filepath) as f:\n",
    "    LDAvis_prepared = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pyLDAvis.display(LDAvis_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
